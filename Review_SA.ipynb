{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f05233-b125-42d0-a29a-2145b0f47c1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1>Sentinental Analysis Classifier</h1>\n",
    "<p>We will be creating a sentinetal analysis model that will classify review as positive or negative. We will be using the first dataset and the multinomial naive bayes classifier along with nltk to classify the review.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c892e13e-3466-4b6b-a331-a42ff3af19e5",
   "metadata": {},
   "source": [
    "<h2>Importing the required libraries</h2>\n",
    "<p>Pandas will be used for handling the data. Nltk will be used to converting the reviews in a training format while sklearn will be used to train and classify the reviews as positive or negative. Pickle is used to save the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c79b69-b9ac-4da7-a6d1-845493520deb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad8bb9-f89f-4659-8b56-d066c02ee6b1",
   "metadata": {},
   "source": [
    "<h2>Downloading the 'stopwords' package</h2>\n",
    "<p>The stop words consists of common words that will be removed from the reviews before analysis</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41858da-2aa0-4fbc-b38d-31e84e8a5cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\danie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507ca6e-b80b-49c2-8b24-30a206d5d5e7",
   "metadata": {},
   "source": [
    "<h2>Importing the data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f4055d-939b-4335-8ecc-3ae9aeb8c08d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite the fact that I have only played a sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I bought this charger in Jul 2003 and it worke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Check out Maha Energy's website. Their Powerex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Reviewed quite a bit of the combo players and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I also began having the incorrect disc problem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Values                                             Review\n",
       "0       1  Despite the fact that I have only played a sma...\n",
       "1       0  I bought this charger in Jul 2003 and it worke...\n",
       "2       1  Check out Maha Energy's website. Their Powerex...\n",
       "3       1  Reviewed quite a bit of the combo players and ...\n",
       "4       0  I also began having the incorrect disc problem..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('review1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6381c65-c446-4a57-a858-0ef033a11010",
   "metadata": {},
   "source": [
    "<h2>Storing the stop words in a variable</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc1ac5d8-663c-401b-ba26-b4435d2cb7b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d57e85d-cfe7-4107-aef8-7cec678e63b9",
   "metadata": {},
   "source": [
    "<h2>Creating a method for preprocessing the text</h2>\n",
    "<p>Before analysis, the text must be in a certain format. The text is converted to lower to prevent problems occuring due to ascii errors A list of common stopwords are removed for the text</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d9b8782-f514-41b3-af42-36735bc6e5e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and special characters\n",
    "    text = ''.join([c for c in text if c.isalnum() or c.isspace()])\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1e7f44-99a2-4a85-8ce7-4ffa8e577f01",
   "metadata": {},
   "source": [
    "<h2>Preprocessing all reviews</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25324d97-6df9-44e6-94d7-4ec8a289607d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecf3f4-8daf-4219-88a1-d3f5a578d1b0",
   "metadata": {},
   "source": [
    "<h2>Converting the reviews in a vectorized format for training and classification</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c99d3bec-c0e1-4ccf-924e-a82f60343622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(df['Review'])\n",
    "y = df['Values']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2232cdb-dae5-4f95-8652-bd291c78bbfb",
   "metadata": {},
   "source": [
    "<h2>Dividing the data into training and testing data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e61657f5-2791-47a4-9310-e69893d251de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac90e2a-1814-4fda-8045-2976af7d8313",
   "metadata": {},
   "source": [
    "<h2>Using the Multinomial Naive Bayes Classifier</h2>\n",
    "<p>The MultinomialNB is a machine learning algorithm used for text classification. It is based on the naive bayes algorithm.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2931def2-29a2-4634-8cc0-9a800bca1891",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bdbc7c-c523-438b-ae75-c71b2bc6387b",
   "metadata": {},
   "source": [
    "<h2>Using the testing data to predict the accuracy of the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ea503b3-e588-49af-898d-ab698b0e1cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d72a24f-ad4d-428b-91b3-562c9aa580b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ad5ec98-0b7b-4ec6-a2c7-2e8bbdbcdc0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82     40086\n",
      "           1       0.82      0.82      0.82     39914\n",
      "\n",
      "    accuracy                           0.82     80000\n",
      "   macro avg       0.82      0.82      0.82     80000\n",
      "weighted avg       0.82      0.82      0.82     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a5e488-8618-4104-9e4b-ed579ac7cbeb",
   "metadata": {},
   "source": [
    "<h2>Saving the model using the pickle package</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efd66188-4648-49bf-a98f-44051bc2373f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('model.pkl','wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
